#!/usr/bin/env python3
"""
Clinical Voice Interpreter - Privacy-First Push-to-Talk Voice Transcription
Based on Stream Deck controls with local Whisper processing and extensible text processing.

This application provides:
- Stream Deck button control for push-to-talk
- Local Whisper transcription (multiple model sizes)
- Extensible text processing (LLM, DeepL, pass-through)
- Cross-platform TTS
- Local persistence with privacy focus
"""

import os
import sys
import logging
import threading
import time
import json
from pathlib import Path
from typing import Optional, Dict, Any, Callable
from dataclasses import dataclass
from datetime import datetime
import tkinter as tk
from tkinter import ttk, messagebox, filedialog

# Aggiungi il percorso src al PYTHONPATH
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# Core components - IMPORT CORRETTI
from stream_deck_controller import StreamDeckController
from audio_recorder import AudioRecorder
from whisper_transcriber import WhisperTranscriber
from text_processor import TextProcessor
from tts_engine import TTSEngine
from session_manager import SessionManager
from config_manager import ConfigManager, ClinicalVoiceConfig
from llm_processor import LLMProcessor

# Load environment configuration
from dotenv import load_dotenv
load_dotenv()

@dataclass
class AppConfig:
    """Application configuration data class"""
    # Audio settings
    sample_rate: int = 16000
    channels: int = 1
    chunk_size: int = 1024
    
    # Whisper settings
    whisper_model: str = "small"  # tiny/base/small/medium/large-v3
    whisper_language: Optional[str] = None  # Auto-detect if None
    
    # Stream Deck settings
    deck_button_index: int = 0
    
    # Text processing
    enable_llm: bool = False
    llm_endpoint: Optional[str] = None
    enable_deepl: bool = False
    deepl_api_key: Optional[str] = None
    
    # TTS settings
    enable_tts: bool = True
    tts_voice: Optional[str] = None
    
    # Storage settings
    output_dir: str = "./output"
    enable_persistence: bool = True
    
    # Privacy settings
    privacy_mode: bool = True  # No cloud calls without explicit consent

class ClinicalVoiceInterpreter:
    """Main application class for the Clinical Voice Interpreter"""
    
    def __init__(self, config: Optional[AppConfig] = None):
        # Initialize logging first
        self._setup_logging()
        
        # Use ConfigManager for proper environment variable handling
        self.config_manager = ConfigManager()
        self.config = self.config_manager.get_config()
        self.running = False
        self.recording = False
        self.current_translation_mode = 'it_to_en'  # Default mode
        # PTT session and timing tracking
        self._key_pressed = False
        self._press_time = 0.0
        self._last_press_time = 0.0
        self._ptt_active = False
        self._stop_timer_id = None
        try:
            self._min_press_ms = int(os.getenv('MIN_PRESS_MS', '350'))
        except Exception:
            self._min_press_ms = 350
        
        # Initialize components
        self.logger.info("Initializing Clinical Voice Interpreter...")
        self._init_components()
        
        # Setup directories
        self._setup_directories()
        
        # Initialize GUI
        self._init_gui()
        
    def _setup_logging(self):
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('clinical_voice_interpreter.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def _init_components(self):
        """Initialize all application components"""
        try:
            # Configuration manager
            self.config_manager = ConfigManager()
            
            # Stream Deck controller
            self.stream_deck = StreamDeckController(
                button_index=self.config.deck_button_index,
                on_press=self._on_button_press,
                on_release=self._on_button_release
            )
            
            # Audio recorder
            self.audio_recorder = AudioRecorder(
                sample_rate=self.config.sample_rate,
                channels=self.config.channels,
                chunk_size=self.config.chunk_size
            )
            # Optionally set a specific input device via env var
            try:
                env_input_idx = os.getenv('AUDIO_INPUT_INDEX')
                if env_input_idx is not None:
                    self.audio_recorder.set_input_device(int(env_input_idx))
                    self.logger.info(f"Audio input device set from env: {env_input_idx}")
            except Exception as e:
                self.logger.warning(f"Could not set audio input from env: {e}")
            
            # Whisper transcriber
            self.transcriber = WhisperTranscriber(
                model_name=self.config.whisper_model,
                language=self.config.whisper_language
            )
            
            # Text processor (extensible for LLM/DeepL)
            self.text_processor = TextProcessor(
                enable_llm=self.config.enable_llm,
                llm_endpoint=self.config.llm_endpoint,
                enable_deepl=self.config.enable_deepl,
                deepl_api_key=self.config.deepl_api_key,
                privacy_mode=self.config.privacy_mode
            )
            
            # TTS engine (supports system or Piper backend)
            self.tts_engine = TTSEngine(
                enabled=self.config.enable_tts,
                voice=self.config.tts_voice,
                rate=self.config.tts_rate,
                backend=getattr(self.config, 'tts_backend', None),
                piper_path=getattr(self.config, 'piper_path', None),
                piper_model=getattr(self.config, 'piper_model', None),
            )
            
            # Session manager for persistence
            self.session_manager = SessionManager(
                output_dir=self.config.output_dir,
                enabled=self.config.enable_persistence
            )
            
            # LLM processor for AI analysis
            self.llm_processor = LLMProcessor(
                openai_api_key=self.config.openai_api_key,
                anthropic_api_key=getattr(self.config, 'anthropic_api_key', None),
                llm_endpoint=self.config.llm_endpoint,
                privacy_mode=self.config.privacy_mode
            )
            
            self.logger.info("All components initialized successfully")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize components: {e}")
            raise
            
    def _setup_directories(self):
        """Create necessary directories"""
        Path(self.config.output_dir).mkdir(parents=True, exist_ok=True)
        self.logger.info(f"Output directory ready: {self.config.output_dir}")
        
    def _init_gui(self):
        """Initialize the minimal GUI interface"""
        self.root = tk.Tk()
        self.root.title("Clinical Voice Interpreter")
        # Larger default size to show translation box without resizing
        self.root.geometry("1000x800")
        try:
            self.root.minsize(900, 700)
        except Exception:
            pass
        
        # Main frame
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Status section
        status_frame = ttk.LabelFrame(main_frame, text="Status", padding="5")
        status_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.status_label = ttk.Label(status_frame, text="Ready to start")
        self.status_label.grid(row=0, column=0, sticky=tk.W)
        
        self.recording_indicator = ttk.Label(status_frame, text="‚óè", foreground="gray")
        self.recording_indicator.grid(row=0, column=1, sticky=tk.E)
        
        # Translation status indicator - single clear line
        translation_status_frame = ttk.Frame(status_frame)
        translation_status_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))
        
        ttk.Label(translation_status_frame, text="Translation:", font=('TkDefaultFont', 8)).grid(row=0, column=0, sticky=tk.W)
        self.translation_status = ttk.Label(translation_status_frame, text="üáÆüáπ IT ‚Üí üá∫üá∏ EN (Riccardo speaks Italian)", font=('TkDefaultFont', 8, 'bold'), foreground='blue')
        self.translation_status.grid(row=0, column=1, sticky=tk.W, padx=(5, 0))
        
        # VU (volume) indicator
        self.vu_bar = ttk.Progressbar(status_frame, orient='horizontal', mode='determinate', maximum=100, length=200)
        self.vu_bar.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(4, 0))
        
        # Configuration section
        config_frame = ttk.LabelFrame(main_frame, text="Configuration", padding="5")
        config_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Whisper model selection
        ttk.Label(config_frame, text="Whisper Model:").grid(row=0, column=0, sticky=tk.W, padx=(0, 5))
        self.model_var = tk.StringVar(value=self.config.whisper_model)
        model_combo = ttk.Combobox(config_frame, textvariable=self.model_var, 
                                 values=["tiny", "base", "small", "medium", "large-v3"],
                                 state="readonly", width=15)
        model_combo.grid(row=0, column=1, sticky=tk.W)
        
        # Auto-save configuration when model changes
        model_combo.bind('<<ComboboxSelected>>', lambda e: self._save_config_changes())
        
        # Input Language selection  
        ttk.Label(config_frame, text="Input Language:").grid(row=1, column=0, sticky=tk.W, padx=(0, 5), pady=(5, 0))
        self.input_language_var = tk.StringVar(value=self.config.whisper_language or "auto")
        input_language_combo = ttk.Combobox(config_frame, textvariable=self.input_language_var,
                                    values=["auto", "en", "it", "es", "fr", "de", "zh", "ar", "bn", "sq"],
                                    state="readonly", width=15)
        input_language_combo.grid(row=1, column=1, sticky=tk.W, pady=(5, 0))
        # Auto-select TTS voice when input language changes
        input_language_combo.bind('<<ComboboxSelected>>', lambda e: self._on_language_change())
        
        # Translation Target Language selection
        ttk.Label(config_frame, text="Translate to:").grid(row=2, column=0, sticky=tk.W, padx=(0, 5), pady=(5, 0))
        self.target_language_var = tk.StringVar(value="en")  # Default to English
        target_combo = ttk.Combobox(config_frame, textvariable=self.target_language_var,
                                   values=["en", "it", "es", "fr", "de", "zh", "ar", "bn", "sq"],
                                   state="readonly", width=15)
        target_combo.grid(row=2, column=1, sticky=tk.W, pady=(5, 0))
        # Auto-select TTS voice when target language changes
        target_combo.bind('<<ComboboxSelected>>', lambda e: self._on_target_language_change())

        # Input Device selection
        ttk.Label(config_frame, text="Input Device:").grid(row=3, column=0, sticky=tk.W, padx=(0, 5), pady=(5, 0))
        self.input_device_var = tk.StringVar(value="")
        self.input_device_combo = ttk.Combobox(
            config_frame,
            textvariable=self.input_device_var,
            values=[],
            state="readonly",
            width=40,
        )
        self.input_device_combo.grid(row=3, column=1, sticky=tk.W, pady=(5, 0))
        self.input_device_combo.bind('<<ComboboxSelected>>', lambda e: self._on_input_device_change())

        # Input Gain selection
        ttk.Label(config_frame, text="Input Gain:").grid(row=4, column=0, sticky=tk.W, padx=(0, 5), pady=(5, 0))
        self.input_gain_var = tk.DoubleVar(value=float(os.getenv('INPUT_GAIN', '1.0') or 1.0))
        self.input_gain_scale = ttk.Scale(
            config_frame,
            from_=0.5,
            to=3.0,
            orient='horizontal',
            variable=self.input_gain_var,
            command=lambda v: self._on_input_gain_change(v),
            length=200
        )
        self.input_gain_scale.grid(row=4, column=1, sticky=tk.W, pady=(5, 0))
        
        # Text processing options
        processing_frame = ttk.LabelFrame(main_frame, text="Text Processing", padding="5")
        processing_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.llm_var = tk.BooleanVar(value=self.config.enable_llm)
        ttk.Checkbutton(processing_frame, text="Enable LLM Processing", 
                       variable=self.llm_var).grid(row=0, column=0, sticky=tk.W)
        
        self.deepl_var = tk.BooleanVar(value=self.config.enable_deepl)
        ttk.Checkbutton(processing_frame, text="Enable DeepL Translation", 
                       variable=self.deepl_var).grid(row=1, column=0, sticky=tk.W)
        
        # DeepL usage counter
        self.usage_label = ttk.Label(processing_frame, text="DeepL: 0/500,000 chars (0%)", 
                                    font=('TkDefaultFont', 8))
        self.usage_label.grid(row=1, column=1, sticky=tk.W, padx=(10, 0))
        
        self.tts_var = tk.BooleanVar(value=self.config.enable_tts)
        ttk.Checkbutton(processing_frame, text="Enable Text-to-Speech", 
                       variable=self.tts_var).grid(row=2, column=0, sticky=tk.W)
        # Internal TTS vars (controls moved to Settings window)
        self.tts_backend_var = tk.StringVar(value=(getattr(self.config, 'tts_backend', None) or 'system'))
        self.tts_voice_var = tk.StringVar(value=self.config.tts_voice or "")
        self.tts_rate_var = tk.IntVar(value=getattr(self.config, 'tts_rate', 200))
        self._piper_name_to_path = {}
        
        # Keyboard instructions
        instructions_frame = ttk.LabelFrame(main_frame, text="Keyboard Controls", padding="5")
        instructions_frame.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(10, 0))
        
        ttk.Label(instructions_frame, text="‚Ä¢ Hold SPACEBAR for Italian‚ÜíEnglish", 
                 font=('TkDefaultFont', 9, 'bold')).grid(row=0, column=0, sticky=tk.W)
        ttk.Label(instructions_frame, text="‚Ä¢ Hold F2 for English‚ÜíItalian", 
                 font=('TkDefaultFont', 9, 'bold')).grid(row=1, column=0, sticky=tk.W)
        ttk.Label(instructions_frame, text="‚Ä¢ Release key to stop and transcribe", 
                 font=('TkDefaultFont', 9)).grid(row=2, column=0, sticky=tk.W)
        ttk.Label(instructions_frame, text="‚Ä¢ Works from anywhere in the window", 
                 font=('TkDefaultFont', 9, 'italic')).grid(row=3, column=0, sticky=tk.W)
        
        # Test button for hotkeys
        test_button = ttk.Button(instructions_frame, text="Test Hotkeys", 
                               command=self._test_hotkeys)
        test_button.grid(row=4, column=0, sticky=tk.W, pady=(5, 0))

        # Microphone test button (records 2s and reports file size/duration)
        mic_test_button = ttk.Button(instructions_frame, text="üéôÔ∏è Test Mic (2s)",
                                   command=lambda: self._test_microphone(2))
        mic_test_button.grid(row=4, column=1, sticky=tk.W, pady=(5, 0))

        # Settings window button
        settings_button = ttk.Button(instructions_frame, text="‚öôÔ∏è Settings", command=self._open_settings_window)
        settings_button.grid(row=4, column=2, sticky=tk.W, pady=(5, 0))
        
        # Right column cards: AI + Service Control
        sidebar = ttk.Frame(main_frame)
        sidebar.grid(row=5, column=0, columnspan=2, sticky=(tk.W, tk.E))
        ai_panel = ttk.LabelFrame(sidebar, text="AI Assistant", padding="10")
        ai_panel.grid(row=0, column=0, sticky=tk.W, padx=(0,10))
        ttk.Button(ai_panel, text="üîç Review Conversation", command=self._review_conversation).grid(row=0, column=0, sticky=tk.W)
        ttk.Button(ai_panel, text="üí¨ Ask AI Question", command=self._show_query_dialog).grid(row=0, column=1, sticky=tk.W, padx=(6,0))
        svc = ttk.LabelFrame(sidebar, text="Service Control", padding="10")
        svc.grid(row=0, column=1, sticky=tk.W)
        self.start_button = ttk.Button(svc, text="üü¢ Start Service", command=self._start_service)
        self.stop_button = ttk.Button(svc, text="‚èπ Stop Service", command=self._stop_service, state="disabled")
        ttk.Button(svc, text="üéôÔ∏è Test Microphone", command=lambda: self._test_microphone(2)).grid(row=1, column=0, sticky=tk.W, pady=(6,0))
        ttk.Button(svc, text="‚öôÔ∏è Settings", command=self._open_settings_window).grid(row=1, column=1, sticky=tk.W, padx=(6,0), pady=(6,0))
        self.start_button.grid(row=0, column=0, sticky=tk.W)
        self.stop_button.grid(row=0, column=1, sticky=tk.W, padx=(6,0))
        
        # Bind Enter key for manual text translation - DISABLED FOR NOW
        # self.output_text.bind('<Return>', self._on_manual_text_entry)
        
        # Configure grid weights
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        main_frame.rowconfigure(6, weight=1)
        output_frame.columnconfigure(0, weight=1)
        output_frame.rowconfigure(0, weight=1)
        
        # Keyboard controls
        self._setup_keyboard_controls()
        # Populate input devices list
        self._populate_input_devices()
        # Apply initial input gain to recorder
        try:
            self.audio_recorder.set_input_gain(self.input_gain_var.get())
        except Exception:
            pass
        # Populate TTS voices and backend UI
        self._populate_tts_voices()
        self._update_tts_backend_ui()
        
        # Auto-select appropriate TTS voice based on current language settings
        self._auto_select_tts_voice_for_current_settings()
        
        # Initialize status indicators
        self._update_language_status_indicators()
        
        # Start VU updates
        self._schedule_vu_update()
        
    def _setup_keyboard_controls(self):
        """Setup keyboard controls to replace Stream Deck functionality"""
        # Bind keyboard events for bidirectional translation
        # Only activate when focus is NOT on the text widget
        self.root.bind('<KeyPress-space>', self._on_global_key_press)
        self.root.bind('<KeyRelease-space>', self._on_global_key_release)
        self.root.bind('<KeyPress-F2>', self._on_global_key_press)
        self.root.bind('<KeyRelease-F2>', self._on_global_key_release)
        
        # Make sure window can receive keyboard events and stays on top when recording
        self.root.focus_set()
        self.root.focus_force()
        
        # Bind focus events to ensure keyboard capture works
        self.root.bind('<FocusIn>', self._on_focus_in)
        self.root.bind('<FocusOut>', self._on_focus_out)
    
    def _on_global_key_press(self, event):
        """Handle global keyboard press - check if text widget has focus"""
        # Don't interfere if text widget has focus (user is typing)
        if self.root.focus_get() == self.output_text:
            return
            
        # Determine translation mode from key
        if event.keysym == 'space':
            self._on_key_press(event, 'it_to_en')
        elif event.keysym == 'F2':
            self._on_key_press(event, 'en_to_it')
    
    def _on_global_key_release(self, event):
        """Handle global keyboard release - check if text widget has focus"""
        # Don't interfere if text widget has focus (user is typing)
        if self.root.focus_get() == self.output_text:
            return
            
        # Determine translation mode from key
        if event.keysym == 'space':
            self._on_key_release(event, 'it_to_en')
        elif event.keysym == 'F2':
            self._on_key_release(event, 'en_to_it')
    
    def _on_key_press(self, event, translation_mode):
        """Handle keyboard key press (start recording)"""
        if not self.running:
            return
            
        now = time.time()
        self._last_press_time = now
        # If a PTT session is already active, just update timestamp and ignore repeats
        if self._ptt_active:
            return

        # Start a new PTT session
        self._ptt_active = True
        self._key_pressed = True
        self._press_time = now
        self.current_translation_mode = translation_mode

        # Switch Piper voice automatically based on current GUI settings
        self._auto_select_tts_voice_for_current_settings()

        # Cancel any pending stop timer
        if self._stop_timer_id is not None:
            try:
                self.root.after_cancel(self._stop_timer_id)
            except Exception:
                pass
            self._stop_timer_id = None

        # Update status to show current mode
        mode_text = "IT‚ÜíEN" if translation_mode == 'it_to_en' else "EN‚ÜíIT"
        self.status_label.config(text=f"Recording - {mode_text} mode...")
        self.logger.info(f"Starting recording in {mode_text} mode")

        # Force Whisper language by mode to reduce hallucinations
        try:
            if translation_mode == 'it_to_en':
                # Forward: from Italian (fixed) to selected target
                forced_lang = 'it'
            else:
                # Reverse: from selected target back to Italian
                forced_lang = self.target_language_var.get() or 'en'
            self.transcriber.update_model(language=forced_lang)
        except Exception:
            pass
        # Ensure Piper voice is switched for the translation target before starting
        try:
            self._switch_piper_voice_for_translation(translation_mode)
        except Exception:
            pass

        self._on_button_press()
    
    def _on_key_release(self, event, translation_mode):
        """Handle keyboard key release (stop recording)"""
        if not self.running:
            return
            
        if not self._ptt_active:
            return
        self._key_pressed = False
        # Schedule a guarded stop that will be canceled if we get a new press soon (auto-repeat)
        def try_stop():
            # If we received a press recently, delay stop again
            gap_ms = (time.time() - self._last_press_time) * 1000.0
            if gap_ms < self._min_press_ms:
                # Reschedule until key is truly released
                self._stop_timer_id = self.root.after(int(self._min_press_ms - gap_ms), try_stop)
                self.logger.info(f"Key released early ({gap_ms:.0f}ms); delaying stop by {int(self._min_press_ms - gap_ms)}ms")
                return
            # Proceed to stop
            self._ptt_active = False
            self._stop_timer_id = None
            self._on_button_release()
        # Start the guarded stop timer
        self._stop_timer_id = self.root.after(0, try_stop)
    
    def _on_focus_in(self, event):
        """Handle window gaining focus"""
        self.status_label.config(text="Service running - SPACEBAR(IT‚ÜíEN) | F2(EN‚ÜíIT) [READY]")
        
    def _on_focus_out(self, event):
        """Handle window losing focus"""
        if self.running:
            self.status_label.config(text="Service running - Click window first [FOCUS NEEDED]")
        
    def _start_service(self):
        """Start the voice interpretation service"""
        try:
            # Update configuration from GUI
            self._update_config_from_gui()
            
            # Start Stream Deck
            self.stream_deck.start()
            
            # Update UI
            self.running = True
            self.start_button.config(state="disabled")
            self.stop_button.config(state="normal")
            self.status_label.config(text="Service running - SPACEBAR(IT‚ÜíEN) | F2(EN‚ÜíIT) [READY]")
            
            self.logger.info("Service started successfully")
            
        except Exception as e:
            self.logger.error(f"Failed to start service: {e}")
            messagebox.showerror("Error", f"Failed to start service: {e}")
            
    def _stop_service(self):
        """Stop the voice interpretation service"""
        try:
            self.running = False
            
            # Stop recording if active
            if self.recording:
                self._stop_recording()
            
            # Stop Stream Deck
            self.stream_deck.stop()
            
            # Update UI
            self.start_button.config(state="normal")
            self.stop_button.config(state="disabled")
            self.status_label.config(text="Service stopped")
            self.recording_indicator.config(foreground="gray")
            
            self.logger.info("Service stopped")
            
        except Exception as e:
            self.logger.error(f"Error stopping service: {e}")
            
    def _update_config_from_gui(self):
        """Update configuration from GUI values"""
        self.config.whisper_model = self.model_var.get()
        self.config.whisper_language = None if self.input_language_var.get() == "auto" else self.input_language_var.get()
        self.config.enable_llm = self.llm_var.get()
        self.config.enable_deepl = self.deepl_var.get()
        self.config.enable_tts = self.tts_var.get()
        
        # Save configuration changes
        self.config_manager.config = self.config
        self.config_manager.save_config()
        
        # Update components with new config
        self.transcriber.update_model(self.config.whisper_model, self.config.whisper_language)
        self.text_processor.update_config(
            enable_llm=self.config.enable_llm,
            enable_deepl=self.config.enable_deepl,
            target_language=self.target_language_var.get()
        )
        self.tts_engine.enabled = self.config.enable_tts
        # Apply TTS voice/rate
        try:
            if self.tts_voice_var.get():
                self.tts_engine.set_voice(self.tts_voice_var.get())
            if self.tts_rate_var.get():
                self.tts_engine.set_rate(int(self.tts_rate_var.get()))
        except Exception:
            pass
    
    def _save_config_changes(self):
        """Save configuration changes immediately"""
        try:
            self.config.whisper_model = self.model_var.get()
            self.config.whisper_language = None if self.input_language_var.get() == "auto" else self.input_language_var.get()
            
            # Update config manager and save
            self.config_manager.config = self.config  
            self.config_manager.save_config()
            
            self.logger.info(f"Configuration saved: model={self.config.whisper_model}, lang={self.config.whisper_language}")
        except Exception as e:
            self.logger.error(f"Failed to save config: {e}")
        
    def _on_button_press(self):
        """Handle Stream Deck button press - start recording"""
        if not self.running or self.recording:
            return
            
        try:
            # Stop any ongoing TTS to avoid echo in mic
            if hasattr(self, 'tts_engine'):
                try:
                    self.tts_engine.stop_speaking()
                except Exception:
                    pass

            self.recording = True
            self.recording_indicator.config(foreground="red")
            self.status_label.config(text="Recording... (release button to stop)")
            
            # Start audio recording
            self.audio_recorder.start_recording()
            self.logger.info("Recording started")
            
        except Exception as e:
            self.logger.error(f"Failed to start recording: {e}")
            self.recording = False
            self.recording_indicator.config(foreground="gray")
            
    def _on_button_release(self):
        """Handle Stream Deck button release - stop recording and process"""
        if not self.recording:
            return
            
        try:
            self.recording = False
            self.recording_indicator.config(foreground="orange")
            self.status_label.config(text="Processing...")
            
            # Stop recording and get audio file
            audio_file = self.audio_recorder.stop_recording()
            
            if audio_file:
                # Quick size-based gate to avoid sending near-empty clips
                try:
                    file_size = os.path.getsize(audio_file)
                    min_bytes = int(os.getenv('MIN_WAV_BYTES', '10000'))  # default ~0.31s @16kHz mono 16-bit
                    if file_size < min_bytes:
                        self.logger.warning(f"Audio file too small ({file_size} bytes), skipping transcription")
                        self.root.after(0, self._update_output, "(no speech detected)", "(no speech detected)")
                        self.root.after(0, self._reset_status)
                        return
                except Exception as e:
                    self.logger.debug(f"Could not stat audio file: {e}")

                # Process in background thread to avoid blocking GUI
                threading.Thread(target=self._process_audio, 
                               args=(audio_file,), daemon=True).start()
            else:
                self._reset_status()
                
        except Exception as e:
            self.logger.error(f"Failed to stop recording: {e}")
            self._reset_status()
            
    def _process_audio(self, audio_file: str):
        """Process the recorded audio file"""
        try:
            start_time = time.time()
            
            # Transcribe with Whisper
            self.logger.info("Starting transcription...")
            transcription = self.transcriber.transcribe(audio_file)
            
            # Additional guard against known hallucinated subtitles
            if transcription:
                tl = transcription.lower()
                if any(m in tl for m in ("qtss", "sottotitoli", "subtitles")):
                    self.logger.warning("Filtered hallucinated subtitle content in post-check")
                    transcription = ""

            if not transcription:
                self.logger.warning("Empty transcription result")
                self.root.after(0, self._update_output, "(no speech detected)", "(no speech detected)")
                self._reset_status()
                return
                
            self.logger.info(f"Transcription completed in {time.time() - start_time:.2f}s")
            
            # Process text with bidirectional translation
            if hasattr(self, 'current_translation_mode'):
                if self.current_translation_mode == 'it_to_en':
                    # Forward: Italian to selected target language
                    tgt = self.target_language_var.get() or 'en'
                    processed_text = self.text_processor.process_text(transcription, target_lang=tgt)
                    self.logger.info(f"Translation: Italian ‚Üí {tgt}")
                elif self.current_translation_mode == 'en_to_it':
                    # Reverse: from selected target language back to Italian
                    processed_text = self.text_processor.process_text(transcription, target_lang='it')
                    self.logger.info("Translation: Target ‚Üí Italian")
                else:
                    # Default fallback
                    processed_text = self.text_processor.process_text(transcription)
            else:
                # Default fallback
                processed_text = self.text_processor.process_text(transcription)
            
            # Add to conversation tracking
            translation_part = ""
            if "‚Üí" in processed_text:
                translation_part = processed_text.split("‚Üí", 1)[1].strip()
                # Remove service tags
                translation_part = translation_part.split("[")[0].strip()
            
            # Determine speaker based on translation direction
            speaker = "patient" if self.current_translation_mode == 'it_to_en' else "doctor"
            
            # Add to conversation
            self.session_manager.add_to_conversation(
                speaker=speaker,
                text=transcription,
                translation=translation_part if translation_part else None,
                translation_direction=self.current_translation_mode
            )
            
            # Update GUI with results
            self.root.after(0, self._update_output, transcription, processed_text)
            
            # TTS output - only speak the translation, not original
            if self.config.enable_tts and processed_text:
                # Extract just the translated part if it contains "‚Üí"
                if "‚Üí" in processed_text:
                    # Get text after the arrow (translated part)
                    translated_part = processed_text.split("‚Üí", 1)[1].strip()
                    # Remove service tags like [DeepL], [Google], [Local]
                    translated_part = translated_part.split("[")[0].strip()
                    self.tts_engine.speak(translated_part)
                else:
                    self.tts_engine.speak(processed_text)
            
            # Save to session
            if self.config.enable_persistence:
                self.session_manager.save_transcription(
                    original_text=transcription,
                    processed_text=processed_text,
                    audio_file=audio_file,
                    model=self.config.whisper_model,
                    processing_config={
                        'llm_enabled': self.config.enable_llm,
                        'deepl_enabled': self.config.enable_deepl
                    }
                )
            
            # Clean up temporary audio file
            try:
                os.unlink(audio_file)
            except OSError:
                pass
                
            self.root.after(0, self._reset_status)
            
        except Exception as e:
            self.logger.error(f"Failed to process audio: {e}")
            self.root.after(0, self._reset_status)
            
    def _on_manual_text_entry(self, event):
        """Handle manual text entry with Enter key"""
        if not self.running:
            return "break"
            
        # Get text from the widget
        text = self.output_text.get(1.0, tk.END).strip()
        if not text:
            return "break"
            
        self.logger.info(f"Manual text entry: '{text}'")
        
        # Process the text (translate it)
        try:
            # Determine translation direction based on current target language
            target_lang = self.target_language_var.get()
            translation_mode = 'it_to_en' if target_lang == 'en' else 'en_to_it'
            
            processed_text = self.text_processor.process_text(
                text, 
                target_lang=target_lang,
                translation_mode=translation_mode
            )
            
            # Add to conversation
            speaker = "patient" if translation_mode == 'it_to_en' else "doctor"
            self.session_manager.add_to_conversation(
                speaker=speaker,
                text=text,
                translation=processed_text,
                translation_direction=translation_mode
            )
            
            # Speak the result
            if self.config.enable_tts and processed_text != text:
                self.tts_engine.speak(processed_text)
                
            # Update display
            self._update_output(text, processed_text)
            
        except Exception as e:
            self.logger.error(f"Failed to process manual text: {e}")
            
        return "break"  # Prevent default Enter behavior
    
    def _update_output(self, original_text: str, processed_text: str):
        """Update the GUI output display"""
        self.logger.info(f"Updating GUI with: '{original_text}'")
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # Clear and update text widget
        self.output_text.delete(1.0, tk.END)
        
        output = f"[{timestamp}] Original: {original_text}\n"
        if processed_text != original_text:
            output += f"[{timestamp}] Processed: {processed_text}\n"
        
        self.output_text.insert(tk.END, output)
        self.output_text.see(tk.END)
        
        # Update DeepL usage counter
        self._update_usage_counter()
    
    def _update_usage_counter(self):
        """Update DeepL usage counter display"""
        try:
            stats = self.text_processor.get_usage_stats()
            chars_used = stats['characters_used']
            max_chars = stats['max_characters'] 
            percentage = stats['percentage_used']
            using_google = stats['using_google_fallback']
            
            if using_google:
                status_text = f"DeepL: LIMIT REACHED ‚Üí Using Google"
                self.usage_label.config(text=status_text, foreground="red")
            elif percentage > 80:
                status_text = f"DeepL: {chars_used:,}/{max_chars:,} chars ({percentage:.1f}%)"
                self.usage_label.config(text=status_text, foreground="orange")
            else:
                status_text = f"DeepL: {chars_used:,}/{max_chars:,} chars ({percentage:.1f}%)"
                self.usage_label.config(text=status_text, foreground="green")
                
        except Exception as e:
            self.logger.warning(f"Could not update usage counter: {e}")
            self.usage_label.config(text="DeepL: Usage unavailable", foreground="gray")
        
    def _reset_status(self):
        """Reset UI status after processing"""
        self.recording_indicator.config(foreground="green")
        if self.running:
            self.status_label.config(text="Service running - SPACEBAR(IT‚ÜíEN) | F2(EN‚ÜíIT) [READY]")
        else:
            self.status_label.config(text="Service stopped")
        
        # Return to green after a short delay
        self.root.after(2000, lambda: self.recording_indicator.config(foreground="gray"))

    def _populate_input_devices(self):
        """Populate the input device combobox with available devices"""
        try:
            devices = self.audio_recorder.get_input_devices()
            values = [f"{d['index']}: {d['name']} (Ch:{d['channels']} {int(d['sample_rate'])}Hz)" for d in devices]
            self.input_device_combo['values'] = values
            if values:
                # Prefer env-selected index if present
                env_idx = os.getenv('AUDIO_INPUT_INDEX')
                selected = values[0]
                if env_idx is not None:
                    for d, v in zip(devices, values):
                        if str(d['index']) == str(env_idx):
                            selected = v
                            break
                self.input_device_var.set(selected)
        except Exception as e:
            self.logger.warning(f"Could not populate input devices: {e}")

    def _on_input_device_change(self):
        """Handle change of selected input device"""
        try:
            sel = self.input_device_var.get()
            idx = int(sel.split(':', 1)[0])
            self.audio_recorder.set_input_device(idx)
            # Persist selection to .env via ConfigManager
            self.config_manager.set_env_var('AUDIO_INPUT_INDEX', str(idx))
            self.logger.info(f"Audio input device set to index {idx}")
        except Exception as e:
            self.logger.error(f"Failed to set input device: {e}")

    def _on_input_gain_change(self, value):
        """Update recorder input gain when slider changes"""
        try:
            gain = float(value)
            self.audio_recorder.set_input_gain(gain)
            # Persist to .env so it sticks next run
            self.config_manager.set_env_var('INPUT_GAIN', f"{gain:.2f}")
        except Exception as e:
            self.logger.warning(f"Failed to apply input gain: {e}")

    def _populate_tts_voices(self):
        """Populate the TTS voice list and select a sensible default"""
        try:
            backend = (self.tts_backend_var.get() or 'system').lower()
            names = []
            display_names = []
            if backend == 'piper':
                self._piper_name_to_path = {}
                # From configured single model
                model_path = getattr(self.config, 'piper_model', None)
                if model_path and os.path.exists(model_path):
                    base = os.path.basename(model_path)
                    self._piper_name_to_path[base] = model_path
                # From scanned directory
                models_dir = getattr(self.config, 'piper_models_dir', None)
                if models_dir and os.path.isdir(models_dir):
                    try:
                        for fn in os.listdir(models_dir):
                            if fn.lower().endswith('.onnx'):
                                full = os.path.join(models_dir, fn)
                                self._piper_name_to_path.setdefault(fn, full)
                    except Exception:
                        pass
                names = list(self._piper_name_to_path.keys())
                display_names = [f"Piper: {n}" for n in names]
            else:
                voices = self.tts_engine.get_voices() if hasattr(self, 'tts_engine') else []
                all_names = [v.get('name') for v in voices if v.get('name')]
                curated = {
                    'Samantha','Alex','Victoria','Daniel','Fiona','Karen',
                    'Alice','Federica',
                    'Thomas','Amelie','Marine',
                    'Anna','Markus','Petra','Steffi',
                    'Jorge','Monica','Paulina','Diego',
                    'Luciana','Joana',
                    'Ting-Ting','Mei-Jia','Li-mu',
                    'Maged','Tarik','Laila'
                }
                names = [n for n in all_names if n in curated]
                if not names:
                    names = all_names[:10]
                display_names = [f"System: {n}" for n in names]

            self.tts_voice_combo['values'] = display_names
            current = self.config.tts_voice
            if current and any(current in dn for dn in display_names):
                for dn in display_names:
                    if current in dn:
                        self.tts_voice_var.set(dn)
                        break
            elif display_names:
                self.tts_voice_var.set(display_names[0])
        except Exception as e:
            self.logger.warning(f"Could not populate TTS voices: {e}")

    def _on_tts_voice_change(self):
        """Apply selected TTS voice and persist"""
        try:
            backend = (self.tts_backend_var.get() or 'system').lower()
            sel = self.tts_voice_var.get() or ''
            voice = sel.replace('Piper: ', '').replace('System: ', '')
            if backend == 'piper':
                # Map display name to full model path and persist
                if voice in self._piper_name_to_path:
                    model_path = self._piper_name_to_path[voice]
                    self.config.tts_voice = voice
                    self.config.piper_model = model_path
                    self.config_manager.set_env_var('PIPER_MODEL', model_path)
                    self._reinit_tts_engine()
            else:
                if voice:
                    self.tts_engine.set_voice(voice)
                    self.config.tts_voice = voice
                    self.config_manager.set_env_var('TTS_VOICE', voice)
        except Exception as e:
            self.logger.warning(f"Failed to set TTS voice: {e}")

    def _on_tts_backend_change(self):
        try:
            backend = (self.tts_backend_var.get() or 'system').lower()
            self.config.tts_backend = backend
            self.config_manager.set_env_var('TTS_BACKEND', backend)
            self._reinit_tts_engine()
            self._update_tts_backend_ui()
            self._populate_tts_voices()
        except Exception as e:
            self.logger.warning(f"Failed to change TTS backend: {e}")

    def _update_tts_backend_ui(self):
        backend = (self.tts_backend_var.get() or 'system').lower()
        show_piper = backend == 'piper'
        try:
            if show_piper:
                model_path = getattr(self.config, 'piper_model', None)
                txt = f"Model: {os.path.basename(model_path)}" if model_path else "Model: (not set)"
                self.piper_model_label.config(text=txt)
                self.piper_model_label.grid()
                self.piper_model_button.grid()
                self.piper_models_dir_button.grid()
            else:
                self.piper_model_label.grid_remove()
                self.piper_model_button.grid_remove()
                self.piper_models_dir_button.grid_remove()
        except Exception:
            pass

    def _select_piper_model(self):
        try:
            initdir = getattr(self.config, 'piper_models_dir', None) or os.path.expanduser("~")
            path = filedialog.askopenfilename(
                title="Select Piper Model",
                initialdir=initdir,
                filetypes=[
                    ("Piper models", "*.onnx *.ONNX *.onnx.gz *.ONNX.GZ"),
                    ("All files", "*")
                ]
            )
            if not path:
                return
            self.config.piper_model = path
            self.config_manager.set_env_var('PIPER_MODEL', path)
            self._reinit_tts_engine()
            self._update_tts_backend_ui()
            self._populate_tts_voices()
        except Exception as e:
            self.logger.error(f"Failed to set Piper model: {e}")

    def _select_piper_models_folder(self):
        try:
            folder = filedialog.askdirectory(title="Select Piper Models Folder")
            if not folder:
                return
            self.config.piper_models_dir = folder
            self.config_manager.set_env_var('PIPER_MODELS_DIR', folder)
            # If no current model, try picking one from folder
            if not getattr(self.config, 'piper_model', None):
                # Search recursively for first .onnx
                for root, _, files in os.walk(folder):
                    for fn in files:
                        low = fn.lower()
                        if low.endswith('.onnx') or low.endswith('.onnx.gz'):
                            self.config.piper_model = os.path.join(root, fn)
                            self.config_manager.set_env_var('PIPER_MODEL', self.config.piper_model)
                            folder = root  # prefer the model's folder for scanning
                            break
                    if getattr(self.config, 'piper_model', None):
                        break
            self._reinit_tts_engine()
            self._update_tts_backend_ui()
            self._populate_tts_voices()
        except Exception as e:
            self.logger.error(f"Failed to set Piper models folder: {e}")

    def _reinit_tts_engine(self):
        try:
            if hasattr(self, 'tts_engine') and self.tts_engine:
                try:
                    self.tts_engine.cleanup()
                except Exception:
                    pass
            self.tts_engine = TTSEngine(
                enabled=self.config.enable_tts,
                voice=self.config.tts_voice,
                rate=self.config.tts_rate,
                backend=getattr(self.config, 'tts_backend', None),
                piper_path=getattr(self.config, 'piper_path', None),
                piper_model=getattr(self.config, 'piper_model', None),
            )
        except Exception as e:
            self.logger.error(f"Failed to reinitialize TTS engine: {e}")

    def _get_piper_voice_for_language(self, language_code: str) -> Optional[str]:
        """Get the best Piper voice for a given language code"""
        # Mapping language codes to preferred Piper models
        language_mapping = {
            'it': ['it_IT-riccardo-x_low.onnx', 'it_IT-paola-medium.onnx'],
            'en': ['en_GB-alan-medium.onnx'],
            'es': ['es_ES-davefx-medium.onnx'],
            'fr': ['fr_FR-mls-medium.onnx'],
            'de': ['de_DE-mls-medium.onnx'],
            'ar': ['ar_JO-kareem-medium.onnx'],
            'zh': ['zh_CN-huayan-medium.onnx'],
        }
        
        try:
            models_dir = getattr(self.config, 'piper_models_dir', None)
            if not models_dir or not os.path.isdir(models_dir):
                return None
                
            # Get preferred models for the language
            preferred_models = language_mapping.get(language_code.lower(), [])
            
            # Check which models are actually available
            for model_name in preferred_models:
                model_path = os.path.join(models_dir, model_name)
                json_path = model_path + ".json"
                
                # Check if both .onnx and .json files exist
                if os.path.exists(model_path) and os.path.exists(json_path):
                    self.logger.info(f"Selected Piper voice for {language_code}: {model_name}")
                    return model_path
                    
            self.logger.warning(f"No Piper voice found for language: {language_code}")
            return None
            
        except Exception as e:
            self.logger.error(f"Error selecting Piper voice for {language_code}: {e}")
            return None

    def _switch_piper_voice_for_translation(self, translation_mode: str):
        """Switch Piper voice based on translation direction"""
        try:
            self.logger.info(f"üîÑ _switch_piper_voice_for_translation called: {translation_mode}")
            
            # Check TTS backend
            current_backend = (self.tts_backend_var.get() or 'system').lower()
            self.logger.info(f"Current TTS backend: {current_backend}")
            
            # Only switch if using Piper backend
            if current_backend != 'piper':
                self.logger.info(f"Not switching voice - backend is {current_backend}, not piper")
                return
                
            # Determine target language based on translation mode
            # TTS should speak the TRANSLATION, not the original
            if translation_mode == 'it_to_en':
                # Italian to English - use English voice for the translated English text
                target_lang = 'en'
                self.logger.info(f"IT‚ÜíEN mode: selecting English voice for translation")
            elif translation_mode == 'en_to_it':
                # English to Italian - use Italian voice for the translated Italian text
                target_lang = 'it'
                self.logger.info(f"EN‚ÜíIT mode: selecting Italian voice for translation")
            else:
                self.logger.warning(f"Unknown translation mode: {translation_mode}")
                return
                
            # Get appropriate Piper voice for target language
            voice_path = self._get_piper_voice_for_language(target_lang)
            if not voice_path:
                return
                
            # Switch to the appropriate voice
            old_model = getattr(self.config, 'piper_model', None)
            if voice_path != old_model:
                self.logger.info(f"Switching Piper voice: {translation_mode} -> {os.path.basename(voice_path)}")
                self.config.piper_model = voice_path
                self._reinit_tts_engine()
                # Update UI to reflect the change
                self._update_tts_backend_ui()
                
        except Exception as e:
            self.logger.error(f"Error switching Piper voice: {e}")

    def _on_language_change(self):
        """Auto-select TTS voice when input language changes"""
        try:
            self.logger.info("üîÑ Input language changed, auto-selecting TTS voice")
            self._auto_select_tts_voice_for_current_settings()
            self._save_config_changes()
            self._update_language_status_indicators()
        except Exception as e:
            self.logger.error(f"Error handling language change: {e}")
    
    def _on_target_language_change(self):
        """Auto-select TTS voice when target language changes"""
        try:
            self.logger.info("üîÑ Target language changed, auto-selecting TTS voice")
            self._auto_select_tts_voice_for_current_settings()
            self._save_config_changes()
            self._update_language_status_indicators()
        except Exception as e:
            self.logger.error(f"Error handling target language change: {e}")
    
    def _auto_select_tts_voice_for_current_settings(self):
        """Auto-select best TTS voice based on current language settings"""
        try:
            # Only auto-select if using Piper backend
            if (self.tts_backend_var.get() or 'system').lower() != 'piper':
                return
            
            # Get current language settings
            target_lang = self.target_language_var.get() or 'en'
            
            # Logic: TTS should speak the TRANSLATION (target language)
            # Use target language for voice selection since TTS speaks the translated text
            preferred_lang = target_lang
            
            self.logger.info(f"Auto-selecting voice for target language: {preferred_lang}")
            
            # Get appropriate Piper voice
            voice_path = self._get_piper_voice_for_language(preferred_lang)
            if not voice_path:
                self.logger.warning(f"No suitable voice found for language: {preferred_lang}")
                return
            
            # Update configuration and TTS engine
            old_model = getattr(self.config, 'piper_model', None)
            if voice_path != old_model:
                self.logger.info(f"Auto-switching TTS voice: {os.path.basename(voice_path)}")
                self.config.piper_model = voice_path
                self.config_manager.set_env_var('PIPER_MODEL', voice_path)
                self._reinit_tts_engine()
                self._update_tts_backend_ui()
                self._populate_tts_voices()
            
            # Always update status indicators to ensure they're in sync
            self._update_language_status_indicators()
                
        except Exception as e:
            self.logger.error(f"Error auto-selecting TTS voice: {e}")
    
    def _update_language_status_indicators(self):
        """Update the translation status indicator"""
        try:
            # Language flag mapping
            lang_flags = {
                'it': 'üáÆüáπ IT', 'en': 'üá∫üá∏ EN', 'es': 'üá™üá∏ ES', 
                'fr': 'üá´üá∑ FR', 'de': 'üá©üá™ DE', 'zh': 'üá®üá≥ ZH',
                'ar': 'üá∏üá¶ AR', 'auto': 'üåê AUTO'
            }
            
            # Voice name mapping
            voice_names = {
                'it_IT-riccardo-x_low.onnx': 'Riccardo',
                'it_IT-paola-medium.onnx': 'Paola',
                'en_GB-alan-medium.onnx': 'Alan',
                'es_ES-davefx-medium.onnx': 'Davefx',
                'fr_FR-mls-medium.onnx': 'MLS',
                'de_DE-mls-medium.onnx': 'MLS',
                'ar_JO-kareem-medium.onnx': 'Kareem',
                'zh_CN-huayan-medium.onnx': 'Huayan'
            }
            
            # Get current settings
            input_lang = self.input_language_var.get() or 'auto'
            output_lang = self.target_language_var.get() or 'en'
            
            # Get current voice info
            current_model = getattr(self.config, 'piper_model', '')
            model_filename = os.path.basename(current_model) if current_model else ''
            voice_name = voice_names.get(model_filename, 'System')
            
            # Create simple status message
            input_flag = lang_flags.get(input_lang, f'{input_lang.upper()}')
            output_flag = lang_flags.get(output_lang, f'{output_lang.upper()}')
            
            status_text = f"{input_flag} ‚Üí {output_flag} ({voice_name} speaks {output_flag})"
            self.translation_status.config(text=status_text)
            
        except Exception as e:
            self.logger.error(f"Error updating language status indicators: {e}")

    def _on_tts_rate_change(self, value):
        """Apply TTS rate updates and persist"""
        try:
            rate = int(float(value))
            self.tts_rate_value.config(text=f"{rate} WPM")
            self.tts_engine.set_rate(rate)
            self.config.tts_rate = rate
            self.config_manager.set_env_var('TTS_RATE', str(rate))
        except Exception as e:
            self.logger.warning(f"Failed to set TTS rate: {e}")

    def _schedule_vu_update(self):
        """Periodic UI update for the VU bar based on input level"""
        try:
            level = {'rms': 0.0}
            if hasattr(self, 'audio_recorder') and self.audio_recorder:
                level = self.audio_recorder.get_level()
            # Map RMS (0..1) to 0..100; apply simple curve to emphasize mid range
            rms = max(0.0, min(1.0, float(level.get('rms', 0.0))))
            # gamma curve for better UX
            gamma = 0.6
            vu_value = int((rms ** gamma) * 100)
            # If not recording, set to 0
            if not self.recording:
                vu_value = 0
            self.vu_bar['value'] = vu_value
        except Exception:
            pass
        finally:
            # Schedule next update
            self.root.after(80, self._schedule_vu_update)

    def _open_settings_window(self):
        try:
            from settings import SettingsWindow
            SettingsWindow(self)
        except Exception as e:
            self.logger.error(f"Failed to open Settings: {e}")
    
    def _test_hotkeys(self):
        """Test hotkey functionality"""
        import tkinter.messagebox as mb
        
        msg = """Test dei controlli tastiera:

1. Clicca OK
2. Prova SPACEBAR (IT‚ÜíEN) 
3. Prova F2 (EN‚ÜíIT)

La text box √® ora read-only quindi i tasti funzioneranno sempre!"""
        
        mb.showinfo("Test Hotkeys", msg)
        
        # Set focus to text box to test hotkeys work even when focused there
        self.output_text.focus_set()

    def _test_microphone(self, seconds: int = 2):
        """Record a short test clip and report stats (non-blocking)."""
        try:
            if self.recording:
                messagebox.showinfo("Recording Busy", "Recording already in progress. Please stop first.")
                return

            # Stop any ongoing TTS to avoid feedback
            if hasattr(self, 'tts_engine'):
                try:
                    self.tts_engine.stop_speaking()
                except Exception:
                    pass

            self.status_label.config(text=f"Testing mic... recording {seconds}s")
            self.recording_indicator.config(foreground="red")
            
            if not self.audio_recorder.start_recording():
                messagebox.showerror("Mic Test Failed", "Could not start audio recording. Check input device and permissions.")
                self._reset_status()
                return

            def finish_test():
                try:
                    audio_file = self.audio_recorder.stop_recording()
                    if not audio_file:
                        self.root.after(0, lambda: messagebox.showwarning("Mic Test", "No audio captured."))
                        return
                    
                    # Compute basic stats
                    try:
                        size = os.path.getsize(audio_file)
                    except Exception:
                        size = -1
                    approx_duration = 0.0
                    if size and size > 44:
                        approx_duration = max(0.0, (size - 44) / (self.config.sample_rate * self.config.channels * 2))
                    
                    def show_result():
                        kb = size/1024.0 if size >= 0 else 0
                        msg = f"File: {audio_file}\nSize: {kb:.1f} KB\nApprox duration: {approx_duration:.2f} s\nSample rate: {self.config.sample_rate} Hz, Channels: {self.config.channels}"
                        messagebox.showinfo("Mic Test Result", msg)
                        # Clean up temp file
                        try:
                            os.unlink(audio_file)
                        except Exception:
                            pass
                        self._reset_status()
                    
                    self.root.after(0, show_result)
                except Exception as e:
                    self.logger.error(f"Mic test failed: {e}")
                    self.root.after(0, lambda: messagebox.showerror("Mic Test Failed", str(e)))
                    self.root.after(0, self._reset_status)

            # Schedule stop after requested seconds without blocking UI
            self.root.after(int(seconds * 1000), lambda: threading.Thread(target=finish_test, daemon=True).start())
        except Exception as e:
            self.logger.error(f"Error during mic test: {e}")
            messagebox.showerror("Mic Test Error", str(e))
    
    def _review_conversation(self):
        """Review current conversation with LLM analysis"""
        if not self.llm_processor.is_available():
            messagebox.showwarning("LLM Not Available", 
                                 "LLM service not configured. Please set OPENAI_API_KEY in .env file.")
            return
            
        if not self.session_manager.current_conversation:
            messagebox.showinfo("No Conversation", 
                              "No conversation to analyze yet. Start recording some dialogue first.")
            return
            
        # Show processing dialog
        self.status_label.config(text="Analyzing conversation with AI...")
        self.root.update()
        
        # Get conversation summary and analyze
        conversation_summary = self.session_manager.get_conversation_summary()
        
        def analyze_in_background():
            try:
                result = self.llm_processor.review_conversation(conversation_summary)
                
                # Show results in GUI thread
                def show_results():
                    if result.get("success"):
                        self._show_llm_response("üîç Analisi Conversazione", result["analysis"])
                    else:
                        messagebox.showerror("Analysis Error", f"Failed to analyze: {result.get('error', 'Unknown error')}")
                    
                    self._reset_status()
                
                self.root.after(0, show_results)
                
            except Exception as e:
                self.logger.error(f"Conversation analysis failed: {e}")
                self.root.after(0, lambda: messagebox.showerror("Error", f"Analysis failed: {str(e)}"))
                self.root.after(0, self._reset_status)
        
        # Run analysis in background thread
        threading.Thread(target=analyze_in_background, daemon=True).start()
    
    def _show_query_dialog(self):
        """Show dialog for direct LLM queries"""
        if not self.llm_processor.is_available():
            messagebox.showwarning("LLM Not Available", 
                                 "LLM service not configured. Please set OPENAI_API_KEY in .env file.")
            return
        
        # Create query dialog
        dialog = tk.Toplevel(self.root)
        dialog.title("LLM Query - Ask AI Assistant")
        dialog.geometry("500x400")
        dialog.transient(self.root)
        dialog.grab_set()
        
        # Query input
        ttk.Label(dialog, text="Ask the AI assistant:", font=('TkDefaultFont', 10, 'bold')).pack(pady=(10, 5))
        
        query_text = tk.Text(dialog, height=4, wrap=tk.WORD)
        query_text.pack(fill=tk.BOTH, padx=10, pady=(0, 10))
        query_text.focus()
        
        # Buttons
        button_frame = ttk.Frame(dialog)
        button_frame.pack(fill=tk.X, padx=10, pady=(0, 10))
        
        def submit_query():
            query = query_text.get("1.0", tk.END).strip()
            if not query:
                messagebox.showwarning("Empty Query", "Please enter a question.")
                return
                
            dialog.destroy()
            
            def process_query():
                try:
                    conversation_context = self.session_manager.get_conversation_summary()
                    result = self.llm_processor.process_query(query, conversation_context)
                    
                    def update_response():
                        if result.get("success"):
                            self._show_llm_response("üí¨ AI Response", result["response"])
                            
                            # Speak the response if TTS enabled
                            if self.config.enable_tts:
                                self.tts_engine.speak(result["response"])
                        else:
                            messagebox.showerror("Query Error", f"Error: {result.get('error', 'Unknown error')}")
                    
                    self.root.after(0, update_response)
                    
                except Exception as e:
                    self.root.after(0, lambda: messagebox.showerror("Error", f"Query failed: {str(e)}"))
            
            threading.Thread(target=process_query, daemon=True).start()
        
        ttk.Button(button_frame, text="Submit Query", command=submit_query).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(button_frame, text="Close", command=dialog.destroy).pack(side=tk.RIGHT)
    
    def _show_llm_response(self, title: str, response: str):
        """Show LLM response in a dedicated window"""
        # Create response window
        response_window = tk.Toplevel(self.root)
        response_window.title(title)
        response_window.geometry("600x400")
        response_window.transient(self.root)
        
        # Response display
        response_text = tk.Text(response_window, wrap=tk.WORD, padx=10, pady=10)
        scrollbar = ttk.Scrollbar(response_window, orient="vertical", command=response_text.yview)
        response_text.configure(yscrollcommand=scrollbar.set)
        
        response_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        response_text.insert(tk.END, response)
        response_text.config(state=tk.DISABLED)
        
    def run(self):
        """Run the application"""
        try:
            self.logger.info("Starting Clinical Voice Interpreter GUI")
            self.root.mainloop()
        except KeyboardInterrupt:
            self.logger.info("Application interrupted by user")
        finally:
            self._cleanup()
            
    def _cleanup(self):
        """Clean up resources"""
        try:
            if self.running:
                self._stop_service()
            
            # Clean up components
            if hasattr(self, 'stream_deck'):
                self.stream_deck.cleanup()
            if hasattr(self, 'audio_recorder'):
                self.audio_recorder.cleanup()
            if hasattr(self, 'transcriber'):
                self.transcriber.cleanup()
            if hasattr(self, 'tts_engine'):
                self.tts_engine.cleanup()
            if hasattr(self, 'session_manager'):
                self.session_manager.cleanup()
            if hasattr(self, 'llm_processor'):
                self.llm_processor.cleanup()
                
            self.logger.info("Application cleanup completed")
        except Exception as e:
            self.logger.error(f"Error during cleanup: {e}")

def main():
    """Main entry point"""
    try:
        # Load configuration from environment/config file
        config = AppConfig()
        
        # Override with environment variables if present
        config.whisper_model = os.getenv('WHISPER_MODEL', config.whisper_model)
        config.whisper_language = os.getenv('WHISPER_LANGUAGE', config.whisper_language)
        config.enable_deepl = bool(os.getenv('DEEPL_API_KEY'))
        config.deepl_api_key = os.getenv('DEEPL_API_KEY')
        config.enable_llm = bool(os.getenv('LLM_ENDPOINT'))
        config.llm_endpoint = os.getenv('LLM_ENDPOINT')
        
        # Create and run application
        app = ClinicalVoiceInterpreter(config)
        app.run()
        
    except Exception as e:
        logging.error(f"Failed to start application: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
